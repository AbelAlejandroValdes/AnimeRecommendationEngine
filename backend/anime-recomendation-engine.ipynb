{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ead9ad",
   "metadata": {},
   "source": [
    "# 1. Fuentes de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d9082781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                              name\n",
      "0     32281                    Kimi no Na wa.\n",
      "1      5114  Fullmetal Alchemist: Brotherhood\n",
      "2     28977                          Gintama°\n",
      "3      9253                       Steins;Gate\n",
      "4      9969                     Gintama&#039;\n",
      "   user_id  anime_id  rating\n",
      "0        1        20      -1\n",
      "1        1        24      -1\n",
      "2        1        79      -1\n",
      "3        1       226      -1\n",
      "4        1       241      -1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12294 entries, 0 to 12293\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   anime_id  12294 non-null  int64 \n",
      " 1   name      12294 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 192.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7813737 entries, 0 to 7813736\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   anime_id  int64\n",
      " 2   rating    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 178.8 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# PASO 1 CARGAR LOS DATOS\n",
    "\n",
    "#Definimos las columnas qur vamos a usar el las tablas : Falta explicacion\n",
    "a_cols = ['anime_id','name']\n",
    "r_cols =['user_id','anime_id','rating']\n",
    "\n",
    "#Cargamos los Dataframes y les aplicamos formato\n",
    "anime_df = pd.read_csv(\"../data/anime.csv\",usecols=a_cols)\n",
    "rating_df = pd.read_csv(\"../data/rating.csv\",sep=',',usecols=r_cols)\n",
    "\n",
    "#Vemos las 5 primeras entradas de las dos tablas\n",
    "print(anime_df.head())\n",
    "print(rating_df.head())\n",
    "\n",
    "\n",
    "#Vemos la informacion de las tablas \n",
    "anime_df.info()\n",
    "rating_df.info()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa638ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  anime_id  rating\n",
      "156        3        20       8\n",
      "157        3       154       6\n",
      "158        3       170       9\n",
      "159        3       199      10\n",
      "160        3       225       9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PASO 2 FILTRADO DE DATOS\n",
    "# Quitamos los ratings invalidos, es decir, los que no tienen una evaluacion como tal \n",
    "ratings_filtrados = rating_df[rating_df['rating'] != -1]\n",
    "#print(ratings_filtrados.head())\n",
    "\n",
    "\n",
    "#FILTRADO DE DATOS \n",
    "#Los animes que nos interesan del ejercicio son los que poseen más de 100 calificaciones\n",
    "#Por ende primero necesitamos saber cuantas calificaciones tiene cada anime\n",
    "# Creamos una variable y de los ratings filtrados guardamos cuantos ratings tienen\n",
    "#cada anime agrupado por su id y contando su rating\n",
    "anime_counts = ratings_filtrados.groupby('anime_id')['rating'].count()\n",
    "#print(anime_counts) \n",
    "\n",
    "#Necesitamos animes más populares con más de 100 calificaciones. \n",
    "#Usamos los datos obtenidos recientemente\n",
    "animes_populares = anime_counts[anime_counts > 100].index # index es el id del dataframe \n",
    "#Ahora necesitamos usar estos animes populares para filtrar los ratings\n",
    "# No nos sirve de nada tener ratings de animes que no sean estos animes populares\n",
    "# con más de 100 reviews asi que los eliminamos \n",
    "rating_df = ratings_filtrados[ratings_filtrados['anime_id'].isin(animes_populares)]\n",
    "\n",
    "# Lo mismo con los usuarios que no tengan mas de 5 ratings\n",
    "# Nos interesa quedarnos con usuarios que hayan calificado al menos 5 animes\n",
    "counts_user = rating_df['user_id'].value_counts() # Contamos cuantos ratings tiene cada usuario\n",
    "# Filtramos el dataframe de ratings para quedarnos solo con los usuarios que tengan 5 o más ratings\n",
    "rating_df = rating_df[rating_df['user_id'].isin(counts_user[counts_user >= 5].index)]       \n",
    "\n",
    "print(rating_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f5765a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas originales: 6194382\n",
      "Filas después de limpiar: 6194375\n"
     ]
    }
   ],
   "source": [
    "# PASO 3 ELIMINAR DUPLICADOS \n",
    "#Identifica filas duplicadas en un DataFrame de ratings (evaluaciones) basándose en las columnas user_id y anime_id,\n",
    "#marcando como True los duplicados excepto la última ocurrencia.\n",
    "duplicates_ratings = rating_df.duplicated(subset=['user_id','anime_id'],keep='last')\n",
    "\n",
    "# Eliminar duplicados directamente, conservando la última ocurrencia\n",
    "cleaned_df = rating_df.drop_duplicates(subset=['user_id','anime_id'], keep='last')\n",
    "\n",
    "\n",
    "# 3. Verificar resultado\n",
    "print(f\"Filas originales: {len(rating_df)}\")\n",
    "print(f\"Filas después de limpiar: {len(cleaned_df)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d871180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     4286.000000\n",
      "mean      1445.259449\n",
      "std       2495.443292\n",
      "min         90.000000\n",
      "25%        207.000000\n",
      "50%        533.500000\n",
      "75%       1515.750000\n",
      "max      33454.000000\n",
      "Name: count, dtype: float64\n",
      "P50 = 533\n",
      "P75 = 1515\n",
      "P90 = 3682\n",
      "P95 = 5947\n",
      "P99 = 12316\n",
      "count    60925.000000\n",
      "mean       101.672253\n",
      "std        133.470987\n",
      "min          5.000000\n",
      "25%         22.000000\n",
      "50%         56.000000\n",
      "75%        129.000000\n",
      "max       2848.000000\n",
      "Name: count, dtype: float64\n",
      "P50 = 56\n",
      "P75 = 129\n",
      "P90 = 245\n",
      "P95 = 347\n",
      "P99 = 650\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PASO 4 LECTURA E INTERPRETACION DE RESULTADOS ESTADÍSTICOS    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analizamos la distribución de la cantidad de calificaciones por anime\n",
    "counts_per_anime = rating_df['anime_id'].value_counts()\n",
    "print(counts_per_anime.describe())\n",
    "# Calcular e imprimir percentiles específicos \n",
    "for p in [50, 75, 90, 95, 99]:\n",
    "    print(f\"P{p} =\", int(counts_per_anime.quantile(p/100)))\n",
    "\n",
    "# Analizamos la distribución de la cantidad de calificaciones por usuario\n",
    "counts_per_user = rating_df['user_id'].value_counts()\n",
    "print(counts_per_user.describe())\n",
    "# Calcular e imprimir percentiles específicos\n",
    "for p in [50, 75, 90, 95, 99]:\n",
    "    print(f\"P{p} =\", int(counts_per_user.quantile(p/100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126738f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  anime_id  rating\n",
      "161        3       341       6\n",
      "167        3      1121       7\n",
      "168        3      1122       7\n",
      "176        3      1764       6\n",
      "178        3      2201       7\n"
     ]
    }
   ],
   "source": [
    "# PASO 5 Identificacion de Outliers\n",
    "# Un outlier es un dato que se encuentra muy alejado del resto de los datos en un conjunto.\n",
    "# Tenemos que eliminarlos para evitar que afecten negativamente a nuestro modelo de recomendacion.\n",
    "MAX_RATINGS_USER = counts_per_user.quantile(0.80) # Definimos un umbral para usuarios con demasiadas calificaciones (outliers)\n",
    "# Filtramos los usuarios que tienen entre 5 y MAX_RATINGS_USER calificaciones\n",
    "valid_users = counts_user[\n",
    "    (counts_user >= 5) &\n",
    "    (counts_user <= MAX_RATINGS_USER)\n",
    "].index\n",
    "\n",
    "MAX_RATINGS_ANIME = counts_per_anime.quantile(0.80) # Definimos un umbral para animes con demasiadas calificaciones (outliers)\n",
    "# Filtramos los animes que tienen entre 100 y MAX_RATINGS_ANIME calificaciones\n",
    "valid_animes = counts_per_anime[\n",
    "    (counts_per_anime >= 100) &\n",
    "    (counts_per_anime <= MAX_RATINGS_ANIME)\n",
    "].index\n",
    "\n",
    "\n",
    "# Filtramos el DataFrame de ratings para quedarnos solo con los usuarios y animes válidos   \n",
    "rating_df = rating_df[\n",
    "    rating_df['user_id'].isin(valid_users) &\n",
    "    rating_df['anime_id'].isin(valid_animes)\n",
    "]\n",
    "print(rating_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "455c5140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3429.000000\n",
      "mean      157.584135\n",
      "std       177.087037\n",
      "min         4.000000\n",
      "25%        37.000000\n",
      "50%        84.000000\n",
      "75%       212.000000\n",
      "max      1116.000000\n",
      "Name: count, dtype: float64\n",
      "P50 = 84\n",
      "P75 = 212\n",
      "P90 = 408\n",
      "P95 = 559\n",
      "P99 = 771\n",
      "count    42285.000000\n",
      "mean        12.778905\n",
      "std         13.602780\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          8.000000\n",
      "75%         18.000000\n",
      "max        112.000000\n",
      "Name: count, dtype: float64\n",
      "P50 = 8\n",
      "P75 = 18\n",
      "P90 = 32\n",
      "P95 = 41\n",
      "P99 = 61\n"
     ]
    }
   ],
   "source": [
    "# PASO 6 VOLVEMOS A LEER E INTERPRETAR RESULTADOS ESTADÍSTICOS   \n",
    "# Analizamos la distribución de la cantidad de calificaciones por anime\n",
    "counts_per_anime = rating_df['anime_id'].value_counts()\n",
    "print(counts_per_anime.describe())\n",
    "# Calcular e imprimir percentiles específicos\n",
    "for p in [50, 75, 90, 95, 99]:\n",
    "    print(f\"P{p} =\", int(counts_per_anime.quantile(p/100)))\n",
    "# Analizamos la distribución de la cantidad de calificaciones por usuario\n",
    "counts_per_user = rating_df['user_id'].value_counts()\n",
    "print(counts_per_user.describe())\n",
    "# Calcular e imprimir percentiles específicos\n",
    "for p in [50, 75, 90, 95, 99]:\n",
    "    print(f\"P{p} =\", int(counts_per_user.quantile(p/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b1b1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  anime_id  rating\n",
      "161        3       341       6\n",
      "167        3      1121       7\n",
      "168        3      1122       7\n",
      "176        3      1764       6\n",
      "178        3      2201       7\n",
      "¿Hunter X Hunter (11061) está en las columnas? False\n"
     ]
    }
   ],
   "source": [
    "# PASO 7 CREACION DE LA MATRIZ DE INTERACCION USUARIO-ANIME\n",
    "anime_ratings = rating_df.pivot_table(index='user_id', columns='anime_id', values='rating', fill_value=0)\n",
    "print(rating_df.head())\n",
    "\n",
    "hunter_en_columnas = 11061 in anime_ratings.columns\n",
    "print(f\"¿Hunter X Hunter (11061) está en las columnas? {hunter_en_columnas}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7829b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "11061",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abela\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 11061",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 2. Obtenemos la similitud para Hunter X Hunter\u001b[39;00m\n\u001b[32m      8\u001b[39m hunter_id = \u001b[32m11061\u001b[39m  \u001b[38;5;66;03m# Usando el ID correcto de Hunter x Hunter\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m similarities = \u001b[43manime_similarity_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhunter_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 3. Ordenamos y filtramos\u001b[39;00m\n\u001b[32m     12\u001b[39m recommended_animes = similarities.sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).drop(hunter_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abela\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abela\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 11061"
     ]
    }
   ],
   "source": [
    "# PASO 8 CREAR LAS RECOMENDACIONES DE ANIME HUNTER X HUNTER CON ID 11061\n",
    "\n",
    "# 1. Cálculo de la similitud entre los animes\n",
    "similarity_matrix = cosine_similarity(anime_ratings.T)\n",
    "anime_similarity_df = pd.DataFrame(similarity_matrix, index=anime_ratings.columns, columns=anime_ratings.columns)\n",
    "\n",
    "# 2. Obtenemos la similitud para Hunter X Hunter\n",
    "hunter_id = 11061 \n",
    "similarities = anime_similarity_df[hunter_id]\n",
    "\n",
    "# 3. Ordenamos y filtramos\n",
    "recommended_animes = similarities.sort_values(ascending=False).drop(hunter_id)\n",
    "\n",
    "# 4. Convertimos a DataFrame y unimos con los nombres\n",
    "recommendations_df = recommended_animes.head(10).reset_index()\n",
    "recommendations_df.columns = ['anime_id', 'similarity_score']\n",
    "\n",
    "# 5. Unimos con los nombres de los animes\n",
    "recommendations_with_names = recommendations_df.merge(anime_df, on='anime_id', how='left')\n",
    "\n",
    "# 6. Mostramos los resultados con nombres\n",
    "print(\"Top 10 animes recomendados para Hunter x Hunter:\")\n",
    "print(recommendations_with_names[['anime_id', 'name', 'similarity_score']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#HUNTER X HUNTER NO SE ENCUNETRA EN LA MATRIZ DE LOS ANIMES PORQUE NO CUMPLE CON LOS REQUISITOS DE FILTRADO\n",
    "#PARA QUE UN ANIME SE ENCUENTRE EN LA MATRIZ DEBE TENER MÁS DE 100 RATINGS Y HUNTER X HUNTER TIENE 93 RATINGS\n",
    "#¿QUE HAGO? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
